---
title: "Project 3"
author: "Jesse DeBolt & Isaac Johnson"
date: "03/16/2023"
output:
  pdf_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
  html_document:
    df_print: paged
---


## Setup
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(tidytext)
library(caret)
library(fastDummies)
library(randomForest)
# https://www.openml.org/d/1590

raw_income = read_csv("openml_1590.csv", na=c("?"))

income = read_csv("openml_1590.csv", na=c("?")) %>%
  drop_na() %>%
  mutate(income_above_50k = class==">50K") %>%
  select(-class) %>%
  dummy_cols(remove_selected_columns = T)

View(income)

```

## Some questions about the data

Please try at least a few of the following:

###* Run PCA on the dataset.
```{r results='hide'}
pr_income <- prcomp(x = select(income, -income_above_50k), scale = T, center = T)

summary(pr_income)
```


### Determine how many principal components are needed to explain half the variation
```{r}
cumulative_proportion <- cumsum(pr_income$sdev^2 / sum(pr_income$sdev^2))

n_components <- min(which(cumulative_proportion >= 0.5))

cat("The number of principal components needed to explain 50% of the variation is", n_components)

```

**Answer:** The number of principal components needed to explain 50% of the variation is 37


* Can you give some interpretation of the principal components?
# Viewing the loadings of each principal component. Loadings allow us to see the individual contribution of each predictor variable to each principal component.
```{r}
lodaings <- rownames_to_column(as.data.frame(pr_income$rotation)) %>%
select(1:6) %>%
filter(abs(PC1) >= 0.35 | abs(PC2) >= 0.35 | abs(PC3) >= 0.35 | abs(PC4) >= 0.35 | abs(PC5) >= 0.35)

```

**Answer:**.........................


* Look at the scree plot. How many PCs would you choose based on that?
```{r}
screeplot(pr_income, type = "lines")

```
**Answer:** We would choose five PCs since it appears as though that is a good representation of the 'elbow'.


* Are the first few Principal Components good predictors of income_above_50k?
# "To do this, you can use the predict() function in R. This function will take a princomp object and a variable as input and return a vector of predicted values for the variable. You can then use the summary() function to get information about the accuracy of the predictions. The rmse attribute of the summary object contains the root mean squared error of the predictions. This can be used to assess how well the principal components predict the variable."
```{r}
prc <- bind_cols(select(income,income_above_50k),as.data.frame(pr_income$x)) %>%
select(1:5)

fit <- train(income_above_50k ~ .,
             data = prc,
             method = "naive_bayes",
             metric = "accuracy",
             trControl = trainControl(method = "cv"))

confusionMatrix(predict(fit, prc),factor(prc$variety))
```







```{r}

# Load the dataset
income <- read.csv("income.csv")

# Calculate the principal components
pca <- prcomp(income)

# Determine how many principal components are needed to explain half the variation
n <- which.min(pca$sdev) - 1

# Provide some interpretation of the principal components
loadings <- pca$loadings

# Decide if the first few principal components  are good predictors of the 'income_above_50k' variable
pred <- predict(pr_income, income$income_above_50k)
summary(pred)

# Determine how well we can predict the 'income_above_50k' variable using the first five or six principal components and just the first two
pred5 <- predict(pca, income$income_above_50k, ncomp=5)
summary(pred5)
pred2 <- predict(pca, income$income_above_50k, ncomp=2)
summary(pred2)



pred <- predict(pca, income$income_above_50k)
summary(pred)



set.seed(555)

# control <- trainControl(method = "cv", number = 5)
# 
# income_index <- createDataPartition(income$income_above_50k, p = 0.80, list = FALSE)
# 
# train <- income[ income_index, ]
# test <- income[-income_index, ]
# 
# fit <- train(income ~ .,
#              data = train,
#              trControl = control,
#              method = "rf")

formula <- as.formula("income_above_50k ~ PC1 + PC2")

# Fit a logistic regression model using the first two principal components
model <- train(formula,
               data = pr_income$rotation,
               method = "glmnet",
               family = "binomial",
               trControl = trainControl(method = "cv"))

```
**Answer:** ..............


* How well can you predict income_above_50k using the first 5 or 6 principal components? How about only the first 2?
```{r}

```


* Can you gain any insights into the data based on k-means clustering? 
```{r}


```



* Can you visualize and interpret some or all of your clusters?



* Using any and all techniques we have learned, build the best predictive model for income_above_50k that you can. What are your best features? What model did you use? What interpretations can you draw?



* What metric can you use to assess model performance? Why is that a good choice of metric in this case?



* What are some key insights you found through your analysis?

Please remember: a statement like "PC2 is not a meaningful predictor for our modeling problem" is a great insight; sometimes things don't work!

10 pts PCA

* analysis and interpretation of factor loadings
* discussion of scree plot and/or analysis of some density plots of PCs
* meaningful interpretation / discussion of conclusions 

10 pts k-means

* discussion for choosing number of clusters
* analysis of cluster centers
* bivariate chart(s) against meaningful variables and/or analysis of density plots
* meaningful interpretation / discussion of conclusions 

10 pts supervised learning

* feature engineering / selection, whether with PCA or otherwise
* interpretation of variable importance, coefficients if applicable
* justification of choice of metric
* discussion of choice or tuning of hyperparameters, if any
* meaningful discussion of predictive power and conclusions from model

Please be prepared to 

* Submit your Rmd + compiled html or pdf, *and*
* Present your findings to the class in a compelling way, speaking for 10 minutes or so. You don't need to cover everything in your analysis that you submit to me, focus on the fun / interesting / compelling highlights or challenges.


```{r}

```

