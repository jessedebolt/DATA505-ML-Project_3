---
title: "Project 3"
author: "Jesse DeBolt & Isaac Johnson"
date: "03/16/2023"
output:
  pdf_document:
    df_print: kable
    fig_width: 11
    fig_height: 8
  html_document:
    df_print: paged
---


## Setup
```{r setup, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
library(tidytext)
library(caret)
library(fastDummies)
library(randomForest)
# https://www.openml.org/d/1590

raw_income = read_csv("openml_1590.csv", na=c("?"))

income = read_csv("openml_1590.csv", na=c("?")) %>%
  drop_na() %>%
  mutate(income_above_50k = class==">50K") %>%
  select(-class) %>%
  dummy_cols(remove_selected_columns = T)

View(income)

```

## Some questions about the data

Please try at least a few of the following:

* Run PCA on the dataset. How many principal components do you need to explain half the variation? 
```{r}
pr_income <- prcomp(x = select(income, -income_above_50k), scale = T, center = T)

summary(pr_income)

# run the component breakdown
```
**Answer:** PC37 - Cumulative Proportion = 0.50628


* Can you give some interpretation of the principal components?
```{r}
rownames_to_column(as.data.frame(pr_income$rotation)) %>%
select(1:6) %>%
filter(abs(PC1) >= 0.25 | abs(PC2) >= 0.25 | abs(PC3) >= 0.25 | abs(PC4) >= 0.25 | abs(PC5) >= 0.25)

```

**Answer:**.........................


* Look at the scree plot. How many PCs would you choose based on that?
```{r}
screeplot(pr_income, type = "lines")

```
**Answer:** We would choose five PCs since it appears as though that is a good representation of the 'elbow'.


* Are the first few Principal Components good predictors of income_above_50k?
```{r}
rownames_to_column(as.data.frame(pr_income$rotation)) %>%
select(1:6) %>%
filter(abs(PC1) >= 0.25 | abs(PC2) >= 0.25 | abs(PC3) >= 0.25 | abs(PC4) >= 0.25 | abs(PC5) >= 0.25)

```
**Answer:** ..............


* How well can you predict income_above_50k using the first 5 or 6 principal components? How about only the first 2?
```{r}
# Factor loadings
#pr_income$rotation

prc <- bind_cols(select(wine,variety),as.data.frame(pr_wine$x)) %>%
select(1:5)# %>%
#rename("pricey"=PC1, "quality_french_oak"=PC2, "crappy_french_oak"=PC3, "willamette_valley"=PC4)

```


* Can you gain any insights into the data based on k-means clustering? 
```{r}


```



* Can you visualize and interpret some or all of your clusters?



* Using any and all techniques we have learned, build the best predictive model for income_above_50k that you can. What are your best features? What model did you use? What interpretations can you draw?



* What metric can you use to assess model performance? Why is that a good choice of metric in this case?



* What are some key insights you found through your analysis?

Please remember: a statement like "PC2 is not a meaningful predictor for our modeling problem" is a great insight; sometimes things don't work!

10 pts PCA

* analysis and interpretation of factor loadings
* discussion of scree plot and/or analysis of some density plots of PCs
* meaningful interpretation / discussion of conclusions 

10 pts k-means

* discussion for choosing number of clusters
* analysis of cluster centers
* bivariate chart(s) against meaningful variables and/or analysis of density plots
* meaningful interpretation / discussion of conclusions 

10 pts supervised learning

* feature engineering / selection, whether with PCA or otherwise
* interpretation of variable importance, coefficients if applicable
* justification of choice of metric
* discussion of choice or tuning of hyperparameters, if any
* meaningful discussion of predictive power and conclusions from model

Please be prepared to 

* Submit your Rmd + compiled html or pdf, *and*
* Present your findings to the class in a compelling way, speaking for 10 minutes or so. You don't need to cover everything in your analysis that you submit to me, focus on the fun / interesting / compelling highlights or challenges.


```{r}

```

